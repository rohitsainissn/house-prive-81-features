{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "007a0ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prayer/anaconda3/lib/python3.10/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b560e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv', index_col='Id')\n",
    "X_test = pd.read_csv('test.csv', index_col='Id')\n",
    "\n",
    "# Separate X_train and y_train\n",
    "X_train = train.drop('SalePrice', axis=1)\n",
    "y_train = train['SalePrice']\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numerical_cols = X_train.select_dtypes(include=['number']).columns\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66081fbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assume you have X_train, X_cv, X_test, y_train, numerical_cols, and categorical_cols defined\n",
    "\n",
    "# Fill missing values\n",
    "X_train[numerical_cols] = X_train[numerical_cols].fillna(X_train[numerical_cols].median())\n",
    "X_train[categorical_cols] = X_train[categorical_cols].fillna('miss')\n",
    "\n",
    "X_test[numerical_cols] = X_test[numerical_cols].fillna(X_test[numerical_cols].median())\n",
    "X_test[categorical_cols] = X_test[categorical_cols].fillna('miss')\n",
    "\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b385603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize numerical columns\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_cv[numerical_cols] = scaler.transform(X_cv[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f4aad49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical columns\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "X_train_encoded = encoder.fit_transform(X_train[categorical_cols])\n",
    "X_cv_encoded = encoder.transform(X_cv[categorical_cols])\n",
    "X_test_encoded = encoder.transform(X_test[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6544ac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the column names for the one-hot encoded features\n",
    "encoded_feature_names = encoder.get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Create DataFrames from the encoded arrays\n",
    "X_train_encoded_df = pd.DataFrame(X_train_encoded, columns=encoded_feature_names,index = X_train.index)\n",
    "X_cv_encoded_df = pd.DataFrame(X_cv_encoded, columns=encoded_feature_names,index = X_cv.index)\n",
    "X_test_encoded_df = pd.DataFrame(X_test_encoded, columns=encoded_feature_names,index = X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b444c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the encoded categorical columns with the numerical columns\n",
    "X_train = pd.concat([X_train_encoded_df, X_train[numerical_cols]],axis=1)\n",
    "X_cv = pd.concat([X_cv_encoded_df, X_cv[numerical_cols]], axis=1)\n",
    "X_test = pd.concat([X_test_encoded_df, X_test[numerical_cols]] ,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5375a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4608978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# List of algorithms with hyperparameters for tuning\n",
    "algorithms = [\n",
    "    (LinearRegression(), {}),\n",
    "    (DecisionTreeRegressor(), {'max_depth': [3, 5, 7]}),\n",
    "    (RandomForestRegressor(), {'n_estimators': [50, 100, 150], 'max_depth': [3, 5, 7]}),\n",
    "    (GradientBoostingRegressor(), {'n_estimators': [50, 100, 150], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 5, 7]}),\n",
    "    (SVR(), {'C': [0.1, 1, 10], 'gamma': [0.1, 1, 10]}),\n",
    "    (KNeighborsRegressor(), {'n_neighbors': [3, 5, 7]}),\n",
    "    (Ridge(), {'alpha': [0.1, 1, 10]}),\n",
    "    (Lasso(), {'alpha': [0.1, 1, 10]}),\n",
    "    (ElasticNet(), {'alpha': [0.1, 1, 10], 'l1_ratio': [0.1, 0.5, 0.9]}),\n",
    "    (AdaBoostRegressor(), {'n_estimators': [50, 100, 150], 'learning_rate': [0.01, 0.1, 0.2]}),\n",
    "    (ExtraTreesRegressor(), {'n_estimators': [50, 100, 150], 'max_depth': [3, 5, 7]}),\n",
    "    (GaussianProcessRegressor(), {}),\n",
    "    (KernelRidge(), {'alpha': [0.1, 1, 10], 'kernel': ['linear', 'poly', 'rbf']}),\n",
    "    (MLPRegressor(), {'hidden_layer_sizes': [(50,), (100,), (150,)], 'activation': ['relu', 'tanh']}),\n",
    "    (XGBRegressor(), {'n_estimators': [50, 100, 150], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 5, 7]}),\n",
    "]\n",
    "# Loop through each algorithm\n",
    "for algo, param_grid in algorithms:\n",
    "    grid_search = GridSearchCV(estimator=algo, param_grid=param_grid, cv=5, n_jobs=-1, scoring='r2')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    y_pred = grid_search.best_estimator_.predict(X_cv)\n",
    "    r2 = r2_score(y_cv, y_pred)\n",
    "    print(f\"{algo.__class__.__name__}: Best Parameters - {grid_search.best_params_}, Best R2 Score - {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8788ce69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# List of algorithms with hyperparameters for tuning\n",
    "algorithms = [\n",
    "   \n",
    "#     (GradientBoostingRegressor(), {'n_estimators': [50,70, 100,120, 150,180,200,250,350], 'learning_rate': [0.01,.05, 0.09,.1,.13,.19, 0.2,.25,.3], 'max_depth': [1,2,3,4 ,5, 7,10,15]}),\n",
    "#     (KernelRidge(), {'alpha': [.001,.05,.075,0.1,.15,.2,.3,.6, 1,2,5, 10], 'kernel': ['linear', 'poly', 'rbf']}),\n",
    "    (XGBRegressor(), {'n_estimators': [50, 150,200,250,300,325,350,375,400,450,500,600], 'learning_rate': [0.01,.05 ,0.09,.1,.125,.13,.15,.17,.19, 0.2,.3], 'max_depth': [1,2,3,4 ,5, 7,10,15]}),\n",
    "]\n",
    "\n",
    "\n",
    "# Loop through each algorithm\n",
    "for algo, param_grid in tqdm(algorithms):\n",
    "    grid_search = GridSearchCV(estimator=algo, param_grid=param_grid, cv=5, n_jobs=-1, scoring='r2')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    y_pred = grid_search.best_estimator_.predict(X_cv)\n",
    "    r2 = r2_score(y_cv, y_pred)\n",
    "    print(f\"{algo.__class__.__name__}: Best Parameters - {grid_search.best_params_}, Best R2 Score - {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b6522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(learning_rate= 0.13, max_depth= 3, n_estimators= 350)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_cv)\n",
    "r2 = r2_score(y_cv, y_pred)\n",
    "SalePrice = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf34bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17a8157",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] = X_test.index\n",
    "submission['SalePrice'] = SalePrice\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c8f79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming submission is your DataFrame\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc2f53c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90a3393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe69a25a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
